{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de0af5e607d471f813e93ce09541a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments\n",
    "from doctransformers import DocDataset, DocTrainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load and preprocess the docdataset\n",
    "docdata = DocDataset.load_from_disk(\"example/data\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "docdata.preprocess(tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Prepare TrainingArguments as you would for a transformers Trainer\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "id2label = {1: \"POS\", 0: \"NEG\"}\n",
    "label2id = {\"POS\": 1, \"NEG\": 0}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                num_labels=2, id2label=id2label, label2id=label2id).to(\"cuda\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return acc.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"example/model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb33cf1af8e34644a9e23c30f82e5b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Selecting chunks:   0%|          | 0/160005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db5dcdcee3c446a794e22cb58b71df35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Selecting chunks:   0%|          | 0/160005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Init doctrainer\n",
    "clf = RandomForestClassifier(n_jobs=8, verbose=1) # The random forest classifier to classify the documents \n",
    "\n",
    "trainer = DocTrainer(\n",
    "    model=model,\n",
    "    doc_classifier=clf,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    doc_dataset=docdata,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmojio\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\alexf\\Desktop\\HSU\\projects\\doctransformers\\wandb\\run-20240715_123051-rc1hboaj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mojio/huggingface/runs/rc1hboaj' target=\"_blank\">blooming-violet-22</a></strong> to <a href='https://wandb.ai/mojio/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mojio/huggingface' target=\"_blank\">https://wandb.ai/mojio/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mojio/huggingface/runs/rc1hboaj' target=\"_blank\">https://wandb.ai/mojio/huggingface/runs/rc1hboaj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba74bc2fa55a48eb8e2dbb2c69027c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5047 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4665, 'learning_rate': 1.8018624925698435e-05, 'epoch': 0.1}\n",
      "{'loss': 0.4073, 'learning_rate': 1.603724985139687e-05, 'epoch': 0.2}\n",
      "{'loss': 0.3672, 'learning_rate': 1.4055874777095306e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3583, 'learning_rate': 1.2074499702793741e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3355, 'learning_rate': 1.0093124628492174e-05, 'epoch': 0.5}\n",
      "{'loss': 0.3399, 'learning_rate': 8.11174955419061e-06, 'epoch': 0.59}\n",
      "{'loss': 0.3252, 'learning_rate': 6.130374479889043e-06, 'epoch': 0.69}\n",
      "{'loss': 0.3166, 'learning_rate': 4.148999405587478e-06, 'epoch': 0.79}\n",
      "{'loss': 0.3138, 'learning_rate': 2.1676243312859127e-06, 'epoch': 0.89}\n",
      "{'loss': 0.3055, 'learning_rate': 1.8624925698434714e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4ddd250ece45058b352a1e64f4b5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31056132912635803, 'eval_accuracy': 0.867458935735372, 'eval_runtime': 369.35, 'eval_samples_per_second': 214.609, 'eval_steps_per_second': 13.415, 'epoch': 1.0}\n",
      "{'train_runtime': 1544.2648, 'train_samples_per_second': 52.283, 'train_steps_per_second': 3.268, 'train_loss': 0.35293580197522684, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5047, training_loss=0.35293580197522684, metrics={'train_runtime': 1544.2648, 'train_samples_per_second': 52.283, 'train_steps_per_second': 3.268, 'train_loss': 0.35293580197522684, 'epoch': 1.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the BERT model to embedd chunks\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2306b8a2f5bb43ea9fb40d20e83aba57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding chunks.:   0%|          | 0/160005 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd41f3bdef5741039a7604e5fa65409a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding docs.:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1029451d1e0e44b694cc1b8c5bec6504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding docs.:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:   44.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on eval data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>mcc</th><th>accuracy</th><th>f1-score</th></tr><tr><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.900401</td><td>0.9502</td><td>0.950162</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌──────────┬──────────┬──────────┐\n",
       "│ mcc      ┆ accuracy ┆ f1-score │\n",
       "│ ---      ┆ ---      ┆ ---      │\n",
       "│ f64      ┆ f64      ┆ f64      │\n",
       "╞══════════╪══════════╪══════════╡\n",
       "│ 0.900401 ┆ 0.9502   ┆ 0.950162 │\n",
       "└──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train document classifier\n",
    "trainer.train_head() # Accuracy 0.9502"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Econbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
